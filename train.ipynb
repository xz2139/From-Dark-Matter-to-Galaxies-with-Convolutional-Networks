{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "# import torch.utils.data.distributed\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.datasets as datasets\n",
    "# import torchvision.models as models\n",
    "\n",
    "from torch.utils import data\n",
    "import random\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from args import args\n",
    "from train_f import *\n",
    "from Dataset import Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution_loss_prep(pred,Y):\n",
    "    fixed_ones_conv = nn.Conv3d(1,1,kernel_size = 3, padding = 1)\n",
    "    nn.init.constant_(fixed_ones_conv.weight,1)\n",
    "    fixed_ones_conv.weight.requires_grad = False\n",
    "    conv_pred = fixed_ones_conv(pred)\n",
    "    conv_Y = fixed_ones_conv(Y)\n",
    "    return conv_pred, conv_Y\n",
    "\n",
    "# Convolution loss for MSE, use together with weight\n",
    "def convolution_loss(pred,Y, weight_ratio):\n",
    "    weight_mse_loss = weighted_nn_square_loss(weight_ratio)\n",
    "    conv_pred, conv_Y = convolution_loss_prep(pred,Y)\n",
    "    return weight_mse_loss(con_pred,con_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_nn_loss(weight_ratio):\n",
    "    def weighted(X,Y):\n",
    "        base_loss = F.mse_loss(X,Y,reduction = 'sum')\n",
    "        index = Y > 0\n",
    "        plus_loss = F.mse_loss(X[index],Y[index], reduction = 'sum') if index.any() > 0 else 0\n",
    "        total_loss = base_loss + (weight_ratio -1) * plus_loss\n",
    "        return total_loss/X.shape[0]\n",
    "    return weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([3,2,1, 0, 0])\n",
    "b = torch.Tensor([1,2,100, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1961.8000)\n",
      "tensor(1961.8000)\n"
     ]
    }
   ],
   "source": [
    "criterion1 = weighted_nn_loss(1)\n",
    "criterion2 = nn.MSELoss()\n",
    "print(criterion1(a,b))\n",
    "print(criterion2(a,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        \n",
    "        super(Baseline, self).__init__()\n",
    "        '''\n",
    "        torch.nn.Conv3d: input(N,C,D,H,W)\n",
    "                            output(N,C,Dout,Hout,Wout) \n",
    "        torch.nn.AvgPool3d: input(N,C,D,H,W)\n",
    "                            output(N,C,Dout,Hout,Wout)     \n",
    "        '''\n",
    "        '''\n",
    "        nn.Conv3d(in_channels, out_channels, kernel_size)\n",
    "        nn.AvgPool3d()\n",
    "        '''\n",
    "        self.draft_model = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "#             nn.AvgPool3d(3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(in_ch, out_ch, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "#             nn.AvgPool3d(3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, cube):\n",
    "        cube = self.draft_model(cube)\n",
    "        return cube\n",
    "    \n",
    "class SimpleUnet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        \n",
    "        super(SimpleUnet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.Simple_Unet = nn.Sequential(\n",
    "            self.conv_layer(self.in_channels, 16),\n",
    "            self.conv_layer(16, 16),\n",
    "            nn.AvgPool3d(2),\n",
    "            self.conv_layer(16,32),\n",
    "            nn.AvgPool3d(2),\n",
    "            self.conv_layer(32,64),\n",
    "            self.up_conv_layer(64, 64, 3),\n",
    "            self.conv_layer(64, 32),\n",
    "            self.up_conv_layer(32, 32, 3),\n",
    "            self.conv_layer(32, 16),\n",
    "            self.up_conv_layer(16, 16, 2),\n",
    "            self.conv_layer(16, 8),\n",
    "            self.up_conv_layer(8, 8, 2),\n",
    "            self.conv_layer(8, 4),\n",
    "            self.conv_layer(4, 1)\n",
    "        )\n",
    "    \n",
    "    def conv_layer(self, in_channels, out_channels, kernel_size=3, stride=1, padding=0, bias=True):\n",
    "        layers = nn.Sequential(\n",
    "        nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "        nn.BatchNorm3d(out_channels),\n",
    "        nn.LeakyReLU())\n",
    "        return layers\n",
    "    \n",
    "    def up_conv_layer(self, in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, bias=True):\n",
    "        layers = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            # should be feat_in*2 or feat_in\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.LeakyReLU())\n",
    "        return layers\n",
    "    \n",
    "    \n",
    "    def forward(self, cube):\n",
    "        cube = self.Simple_Unet(cube)\n",
    "        return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "\n",
    "\n",
    "        # add a dimension, from (1, 32, 32, 32) to (1,1,32,32,32)\n",
    "        input = input.unsqueeze(dim = 1).to(device).float()\n",
    "        target = target.unsqueeze(dim = 1).to(device).float()\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.train()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input = input.unsqueeze(dim = 1).to(device).float()\n",
    "            target = target.unsqueeze(dim = 1).to(device).float()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            \n",
    "        print('Test: Time {batch_time.val:.3f} \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'\n",
    "              'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(batch_time=batch_time, loss=losses))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index for the cube, each tuple corresponds to a cude\n",
    "train_data = [(800, 640, 224)]\n",
    "val_data = [(800, 640, 224)]\n",
    "test_data = [(800, 640, 224)]\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pos=list(np.arange(0,1024,32))\n",
    "# ranges=list(product(pos,repeat=3))\n",
    "# # random.shuffle(ranges)\n",
    "# train_data = ranges[:int(np.round(len(ranges)*0.6))]\n",
    "# val_data=ranges[int(np.round(len(ranges)*0.6)):int(np.round(len(ranges)*0.8))]\n",
    "# test_data = ranges[int(np.round(len(ranges)*0.8)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'batch_size': 50,\n",
    "          'shuffle': False,\n",
    "          #'shuffle': True,\n",
    "          'num_workers':20}\n",
    "max_epochs = 100\n",
    "\n",
    "training_set, validation_set = Dataset(train_data), Dataset(val_data)\n",
    "testing_set= Dataset(test_data)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n",
    "testing_generator = data.DataLoader(testing_set, **params)\n",
    "\n",
    "for i, (dark,full) in enumerate(testing_generator):\n",
    "    dark=dark\n",
    "    full=full\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim = 1\n",
    "model = SimpleUnet(dim).to(device)\n",
    "criterion = nn.MSELoss().to(device) #yueqiu\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ys3202/.conda/envs/dark/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/1]\tTime 0.340 (0.340)\tLoss 0.0651 (0.0651)\t\n",
      "Test: Time 0.156 \t\t\t\t\t\t\t\t\t\tLoss 21.5622 (21.5622)\t\n",
      "Epoch: [1][0/1]\tTime 0.281 (0.281)\tLoss 21.5622 (21.5622)\t\n",
      "Test: Time 0.164 \t\t\t\t\t\t\t\t\t\tLoss 1303.5524 (1303.5524)\t\n",
      "Epoch: [2][0/1]\tTime 0.293 (0.293)\tLoss 1303.5524 (1303.5524)\t\n",
      "Test: Time 0.161 \t\t\t\t\t\t\t\t\t\tLoss 58937.8438 (58937.8438)\t\n",
      "Epoch: [3][0/1]\tTime 0.285 (0.285)\tLoss 58937.8438 (58937.8438)\t\n",
      "Test: Time 0.167 \t\t\t\t\t\t\t\t\t\tLoss 16216511.0000 (16216511.0000)\t\n",
      "Epoch: [4][0/1]\tTime 0.293 (0.293)\tLoss 16216511.0000 (16216511.0000)\t\n",
      "Test: Time 0.179 \t\t\t\t\t\t\t\t\t\tLoss 3803902208.0000 (3803902208.0000)\t\n",
      "Epoch: [5][0/1]\tTime 0.284 (0.284)\tLoss 3803902208.0000 (3803902208.0000)\t\n",
      "Test: Time 0.185 \t\t\t\t\t\t\t\t\t\tLoss 658882363392.0000 (658882363392.0000)\t\n",
      "Epoch: [6][0/1]\tTime 0.300 (0.300)\tLoss 658882363392.0000 (658882363392.0000)\t\n",
      "Test: Time 0.189 \t\t\t\t\t\t\t\t\t\tLoss 237700653252608.0000 (237700653252608.0000)\t\n",
      "Epoch: [7][0/1]\tTime 0.327 (0.327)\tLoss 237700653252608.0000 (237700653252608.0000)\t\n",
      "Test: Time 0.184 \t\t\t\t\t\t\t\t\t\tLoss 20743010559983616.0000 (20743010559983616.0000)\t\n",
      "Epoch: [8][0/1]\tTime 0.297 (0.297)\tLoss 20743010559983616.0000 (20743010559983616.0000)\t\n",
      "Test: Time 0.175 \t\t\t\t\t\t\t\t\t\tLoss 1550701297664000.0000 (1550701297664000.0000)\t\n",
      "Epoch: [9][0/1]\tTime 0.299 (0.299)\tLoss 1550701297664000.0000 (1550701297664000.0000)\t\n",
      "Test: Time 0.176 \t\t\t\t\t\t\t\t\t\tLoss 11115662051115008.0000 (11115662051115008.0000)\t\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(training_generator, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    validate(validation_generator, model, criterion)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(800, 640, 224)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
